{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/g+9xqDOnpOqzuh0Mjy3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolasNgo/Gamma-metric/blob/main/INFGRAM_Project_2023_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __DESU IA4HEALTH__\n",
        "# __[23-24] Project INF-GRAM: Artificial intelligence programming__\n",
        "\n",
        "Raquel Urena, Nicolas Ngo\n",
        "\n",
        "### __Objectives:__\n",
        "\n",
        "\n",
        "1.   Import and process an unknown dataset\n",
        "2.   Do some descriptive analysis of the data\n",
        "3.   Compute different classification model\n",
        "4.   Evaluate the models and select the final model\n",
        "\n",
        "\n",
        "### __Context:__\n",
        "For this project, we will be working on biomedical data related to vertebral column conditions. In particular, __disk-hernia__ and __spondylolisthesis__.\n",
        "The first one, __disk-hernia__, is a condition in which the annulus fibrosus (outer portion) of the vertebral disc is torn, enabling the nucleus (inner portion) to herniate or extrude through the fibers. The herniated material can compress the nerves around the disc and create pain that can radiate through the back and sometimes down the arms (if the herniation is in the cervical spine) and legs (if the herniation is in the lumbar spine).\n",
        "The second condition, __spondylolisthesis__ is a slipping of vertebra that occurs, in most cases, at the base of the spine. The extent of slippage determines the grade of __sponylolisthesis__.\n",
        "The two conditions can be diagnosed visually via physical exam, X-ray, MRI and radiology technologies.\n",
        "\n",
        "### __Data:__\n",
        "The dataset _column_3C_ has 310 instances of patients data. Each patient is represented in the dataset by six bio-mechanical attributes derived from the shape and orientation of the pelvis and lumbar spine:\n",
        "\n",
        "*   __pelvic incidence:__ pelvic tilt + sacral slope\n",
        "*   __pelvic tilt:__ is the angle between  a vertical line and the CS segment. Denotes spatial orientation of pelvis.\n",
        "*   __lumbar lordosis angle__\n",
        "*   __sacral slope:__ The sacral slope is the angle of the sacral plateau to the horizontal. The degree of the sacral slope determines the position of the lumbar spine, since the sacral plateau forms the bae of the spine\n",
        "*   __pelvic radius__\n",
        "*   __degree_spondylolisthesis:__ degree of severity of spondylolisthesis. Grade 1 being least severe through to grade 4 most severe.\n",
        "*   __class:__ Disk Hernia (DH), Spondylolisthesis (SL), Normal (NO)\n",
        "\n",
        "### __Expected work__\n",
        "\n",
        "For this project, you will use the 6 variables to build a classification problem to classify the patients. The target variable is _class_. The project consist in building different models from the dataset, evaluate them with different indicators, consider calibration of hyper-parameters and finally decide which model you would keep. You can find the dataset on the Ametice webpage or at this link [https://amubox.univ-amu.fr/s/gApQPASxXtEaCPp](https://amubox.univ-amu.fr/s/gApQPASxXtEaCPp).\n",
        "\n"
      ],
      "metadata": {
        "id": "UnOxOjbGKN_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Task 1: Import and pre-process the dataset__"
      ],
      "metadata": {
        "id": "Ju5vieSqZfNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q1:__ Set-up your environment by importing the libraries that you will need for the rest of the project."
      ],
      "metadata": {
        "id": "eNhDB91NbCHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q2:__ Import the dataset _column_3C.txt_ and do the following checking\n",
        "\n",
        "\n",
        "1.   Display the first lines\n",
        "2.   Display the number of rows and columns\n",
        "3.   Check the data type (all features are supposed to be numeric except class)\n",
        "4.   Check if there is any missing value\n",
        "5.   Give the number of patients/rows in each class of the dataset"
      ],
      "metadata": {
        "id": "btwFE2GsbNQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q3:__ For this work we will now work with 2 classes instead of 3. The new classes will be Normal (NO) and Abnormal (AB), with Abnormal = {Disk Hernia, Spondylolisthesis}. Use Python to generate the new class feature. Display the new repartition of the two classes.\n",
        "_N.B.:_ you can display it in a table, an output or with a graphic."
      ],
      "metadata": {
        "id": "pr5i4TwEb6-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Task 2: Univariate descriptive analysis__"
      ],
      "metadata": {
        "id": "y16PHvnbaTaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q4:__ Compute and display the mean and standard deviation values of each feature."
      ],
      "metadata": {
        "id": "cSSgVc4kcdzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q5:__ Compute and display the mean and standard deviation values for each feature in each class (Normal and Abnormal)."
      ],
      "metadata": {
        "id": "Tlz0GP71co8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q6:__ Give the distribution of each feature and for each class in a graphic (use two histograms, on for each class, in a single plot)."
      ],
      "metadata": {
        "id": "33C5A7q6ddoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q7:__ Compute the correlation matrix. Make some comments about the correlation of the features."
      ],
      "metadata": {
        "id": "nAYNBg_VeA_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q8:__ Split the dataset in two parts, a training sample and a test sample (with 80% of the data in the training sample.)"
      ],
      "metadata": {
        "id": "H8IRO4g-e1v8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Task 3: First classification model the logistic regression__"
      ],
      "metadata": {
        "id": "9UZf465PaaRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q8:__ The very first classification model that you can try is the logistic regression model. Build the logistic model, compute your prediction on the test sample"
      ],
      "metadata": {
        "id": "0_GRVbRYeIqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q9:__ Compute and display the confusion matrix for the test sample"
      ],
      "metadata": {
        "id": "KDrbjrbRfA7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q10:__ Choose some performance indicators to compute from the confusion matrix and present them for the logistic regression."
      ],
      "metadata": {
        "id": "q2nDGv-tfTLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Task 4: Second model__"
      ],
      "metadata": {
        "id": "YmyvkHEzaoRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the task 4 and 5 you have more freedom to choose which model you want to test. But whatever the model you will have to take into account the following things:\n",
        "\n",
        "1.   Give a justification of your choice\n",
        "2.   Use the same train sample as Task 3 to build the model.\n",
        "3.   For each model, use the same performance indicators and display the confusion matrix for the test sample.\n",
        "4.   If there's any parameters to calibrate, first do the default model first (without calibration) and then do your calibration, compare the performances of the calibrated model and the default one on the test sample.\n",
        "\n"
      ],
      "metadata": {
        "id": "DxdvxSMCfbeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Task 5: Third model__"
      ],
      "metadata": {
        "id": "uDV6L-lIaulU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the task 4 and 5 you have more freedom to choose which model you want to test. But whatever the model you will have to take into account the following things:\n",
        "\n",
        "1.   Give a justification of your choice\n",
        "2.   Use the same train sample as Task 3 to build the model.\n",
        "3.   For each model, use the same performance indicators and display the confusion matrix for the test sample.\n",
        "4.   If there's any parameters to calibrate, first do the default model first (without calibration) and then do your calibration, compare the performances of the calibrated model and the default one on the test sample."
      ],
      "metadata": {
        "id": "UVM_VM3Qgm3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Task 6: Comparison of the model and final model__"
      ],
      "metadata": {
        "id": "Z9rY1oqJaxwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q11:__ For the last task, use a table to present the performance of the three model on the test sample and choose which is the final model with some arguments."
      ],
      "metadata": {
        "id": "0vfh6Ag8gp5x"
      }
    }
  ]
}